{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83b3d641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "from collections import Counter\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.tokenize import WordPunctTokenizer \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d826a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq(df):\n",
    "\n",
    "\n",
    "    text=''\n",
    "    for i in df['contenu']:\n",
    "        text+=str(i)\n",
    "    text=text.lower()\n",
    "    \n",
    "    tokens = WordPunctTokenizer().tokenize(text) \n",
    "\n",
    "    stop_words=stopwords.words('french')\n",
    "\n",
    "    ponct=\"!@#$%^&*()_+=-[]{}'\\\";:/?.>,<\\|`~\"\n",
    "\n",
    "    tknz=[]\n",
    "    for i in tokens:\n",
    "        if (i not in stop_words) and (i not in ponct) :\n",
    "            tknz.append(i)\n",
    "\n",
    "\n",
    "    # Instantiate a stemmer\n",
    "    ps = PorterStemmer()\n",
    "    # and stem\n",
    "    stems = [ps.stem(tk) for tk in tknz]\n",
    "    \n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d9fa797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_freq(df):\n",
    "\n",
    "\n",
    "    text=''\n",
    "    for i in df['contenu']:\n",
    "        text+=str(i)\n",
    "    text=text.lower()\n",
    "    \n",
    "    tokens = WordPunctTokenizer().tokenize(text) \n",
    "\n",
    "\n",
    "    stop_words=stopwords.words('french')\n",
    "\n",
    "    ponct=\"!@#$%^&*()_+=-‚Äú[]‚Äô{}'\\\";:/?.>,<\\|`~\"\n",
    "\n",
    "    tknz=[]\n",
    "    for i in tokens:\n",
    "        if (i not in stop_words) and (i not in ponct) :\n",
    "            tknz.append(i)\n",
    "\n",
    "\n",
    "    # Instantiate a stemmer\n",
    "    ps = PorterStemmer()\n",
    "    # and stem\n",
    "    stems = [ps.stem(tk) for tk in tknz]\n",
    "    \n",
    "    count=[i[1] for i in Counter(stems).most_common()]\n",
    "    term=[i[0] for i in Counter(stems).most_common()]\n",
    "\n",
    "\n",
    "    \n",
    "    return [term,count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f2dfd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni_bg_freq(df):\n",
    "    \n",
    "\n",
    "    stems_l=freq(df)\n",
    "    stems=stems_l\n",
    "    bigrams = [w for w in ngrams(stems,n=2)]\n",
    "\n",
    "    unique_bigram=[]\n",
    "    for i in bigrams:\n",
    "\n",
    "        c=i[0]+' '+i[1]\n",
    "        unique_bigram.append(c)\n",
    "\n",
    "\n",
    "    Counter(unique_bigram).most_common()\n",
    "    \n",
    "    count=[i[1] for i in Counter(unique_bigram).most_common()]\n",
    "    term=[i[0] for i in Counter(unique_bigram).most_common()]\n",
    "\n",
    "\n",
    "    \n",
    "    return [term,count]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a955c32d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcleantext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clean\n\u001b[1;32m----> 2\u001b[0m clean(\u001b[43mtext\u001b[49m, no_emoji\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m text\u001b[38;5;241m=\u001b[39m[clean(i, no_emoji\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontenu\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "from cleantext import clean\n",
    "clean(text, no_emoji=True)\n",
    "text=[clean(i, no_emoji=True) for i in df['contenu']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94404f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sample text contains laughing emojis\n"
     ]
    }
   ],
   "source": [
    "#import clean function\n",
    "from cleantext import clean\n",
    "\n",
    "#provide string with emojis\n",
    "text = \"This sample text contains laughing emojis üòÄ üòÉ üòÑ üòÅ üòÜ üòÖ üòÇ ü§£\"\n",
    "\n",
    "#print text after removing the emojis from it\n",
    "print(clean(text, no_emoji=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca45d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_freq(df):\n",
    "    \n",
    "    text=[clean(i, no_emoji=True) for i in df['contenu']]\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit(text)\n",
    "    \n",
    "    idf=list(vectorizer.idf_)\n",
    "    dicti=vectorizer.vocabulary_\n",
    "\n",
    "    mot=list(dicti.keys())\n",
    "    index=list(dicti.values())\n",
    "    \n",
    "    return [idf,mot,index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d322f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63528602",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq=clean_freq(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2befa428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apr√®</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cett</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suit</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>publicit√©</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>m√©gaphon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>d√©lire</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>part</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>upqxo7lux7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1574 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  count\n",
       "0              a     75\n",
       "1           apr√®     43\n",
       "2           cett     40\n",
       "3           suit     33\n",
       "4      publicit√©     31\n",
       "...          ...    ...\n",
       "1569    m√©gaphon      1\n",
       "1570      d√©lire      1\n",
       "1571        part      1\n",
       "1572           4      1\n",
       "1573  upqxo7lux7      1\n",
       "\n",
       "[1574 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# List1\n",
    "word = word_freq[0]\n",
    "\n",
    "# List2\n",
    "count = word_freq[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get the list of tuples from two lists.\n",
    "# and merge them by using zip().\n",
    "list_of_tuples = list(zip(word,count))\n",
    "\n",
    "# Assign data to tuples.\n",
    "list_of_tuples\n",
    "\n",
    "\n",
    "# Converting lists of tuples into\n",
    "# pandas Dataframe.\n",
    "words = pd.DataFrame(list_of_tuples,columns=['word','count'])\n",
    "\n",
    "# Print data.\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a300c700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>suit apr√®</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apr√® cett</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cett publicit√©</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‚Äù, a</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>voir √©galement</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>vid√©o chrono</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>capitol january6thcmt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3223</th>\n",
       "      <td>january6thcmt january6thcommitteehearingsp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3224</th>\n",
       "      <td>com upqxo7lux7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225</th>\n",
       "      <td>upqxo7lux7 ‚Äî</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3226 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          bigram  count\n",
       "0                                      suit apr√®     31\n",
       "1                                      apr√® cett     31\n",
       "2                                 cett publicit√©     31\n",
       "3                                           ‚Äù, a     12\n",
       "4                                 voir √©galement     10\n",
       "...                                          ...    ...\n",
       "3221                                vid√©o chrono      1\n",
       "3222                       capitol january6thcmt      1\n",
       "3223  january6thcmt january6thcommitteehearingsp      1\n",
       "3224                              com upqxo7lux7      1\n",
       "3225                                upqxo7lux7 ‚Äî      1\n",
       "\n",
       "[3226 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "uni_bg_freq=uni_bg_freq(df)\n",
    "# List1\n",
    "word = uni_bg_freq[0]\n",
    "\n",
    "# List2\n",
    "count = uni_bg_freq[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get the list of tuples from two lists.\n",
    "# and merge them by using zip().\n",
    "list_of_tuples = list(zip(word,count))\n",
    "\n",
    "# Assign data to tuples.\n",
    "list_of_tuples\n",
    "\n",
    "\n",
    "# Converting lists of tuples into\n",
    "# pandas Dataframe.\n",
    "bigram = pd.DataFrame(list_of_tuples,columns=['bigram','count'])\n",
    "\n",
    "# Print data.\n",
    "bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e064489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1014</td>\n",
       "      <td>maroc</td>\n",
       "      <td>3.662588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>931</td>\n",
       "      <td>la</td>\n",
       "      <td>3.374906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1240</td>\n",
       "      <td>police</td>\n",
       "      <td>4.068053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016</td>\n",
       "      <td>marocaine</td>\n",
       "      <td>4.068053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1160</td>\n",
       "      <td>ouvert</td>\n",
       "      <td>3.151762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>961</td>\n",
       "      <td>lisant</td>\n",
       "      <td>4.068053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>1033</td>\n",
       "      <td>megaphone</td>\n",
       "      <td>4.068053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>518</td>\n",
       "      <td>delire</td>\n",
       "      <td>3.662588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>1179</td>\n",
       "      <td>part</td>\n",
       "      <td>4.068053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>1670</td>\n",
       "      <td>upqxo7lux7</td>\n",
       "      <td>4.068053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1741 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index        word        tf\n",
       "0      1014       maroc  3.662588\n",
       "1       931          la  3.374906\n",
       "2      1240      police  4.068053\n",
       "3      1016   marocaine  4.068053\n",
       "4      1160      ouvert  3.151762\n",
       "...     ...         ...       ...\n",
       "1736    961      lisant  4.068053\n",
       "1737   1033   megaphone  4.068053\n",
       "1738    518      delire  3.662588\n",
       "1739   1179        part  4.068053\n",
       "1740   1670  upqxo7lux7  4.068053\n",
       "\n",
       "[1741 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "tf_freq=tf_freq(df)\n",
    "# List1\n",
    "tf = tf_freq[0]\n",
    "\n",
    "# List2\n",
    "word = tf_freq[1]\n",
    "\n",
    "# List2\n",
    "index = tf_freq[2]\n",
    "\n",
    "\n",
    "# get the list of tuples from two lists.\n",
    "# and merge them by using zip().\n",
    "list_of_tuples = list(zip(index,word,tf))\n",
    "\n",
    "# Assign data to tuples.\n",
    "list_of_tuples\n",
    "\n",
    "\n",
    "# Converting lists of tuples into\n",
    "# pandas Dataframe.\n",
    "tf = pd.DataFrame(list_of_tuples,columns=['index','word','tf'])\n",
    "\n",
    "# Print data.\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e98128",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# List1\n",
    "title = huff[0]+lematin[0]+lavieeco[0]\n",
    "\n",
    "# List2\n",
    "link = huff[1]+lematin[1]+lavieeco[1]\n",
    "\n",
    "# List1\n",
    "contenu = huff[2]+lematin[2]+lavieeco[2]\n",
    "\n",
    "\n",
    "# get the list of tuples from two lists.\n",
    "# and merge them by using zip().\n",
    "list_of_tuples = list(zip(title,link, contenu))\n",
    "\n",
    "# Assign data to tuples.\n",
    "list_of_tuples\n",
    "\n",
    "\n",
    "# Converting lists of tuples into\n",
    "# pandas Dataframe.\n",
    "df = pd.DataFrame(list_of_tuples,columns=['title','link', 'contenu'])\n",
    "\n",
    "# Print data.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a0010eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "words.to_csv('words.csv',index=False)\n",
    "bigram.to_csv('bigram.csv',index=False)\n",
    "tf.to_csv('tf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfd80f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
